{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingesting a Website into ApertureDB\n",
    "\n",
    "This notebook shows how to take web content and load it into ApertureDB so that it can be used in a RAG chain to answer questions.\n",
    "\n",
    "First we need to install a few libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet --upgrade aperturedb langchain langchain-community langchainhub gpt-web-crawler Twisted gpt4all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawl the Website\n",
    "\n",
    "We're going to use the `gpt-web-crawler` package to crawl a website for us.\n",
    "\n",
    "First we grab the default configuration file.  This is where you can insert API keys for advanced services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/Tim-Saijun/gpt-web-crawler/refs/heads/main/config_template.py -O config.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the actual crawl.  We've configured this to point to our documentation website, but feel free to change the starting URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_URLS = \"https://docs.aperturedata.io/\"\n",
    "MAX_PAGES = 1000\n",
    "OUTPUT_FILE = \"output.json\"\n",
    "\n",
    "# Delete the output file if it exists\n",
    "import os\n",
    "if os.path.exists(OUTPUT_FILE):\n",
    "    os.remove(OUTPUT_FILE)\n",
    "\n",
    "from gpt_web_crawler import run_spider, NoobSpider\n",
    "\n",
    "run_spider(NoobSpider, \n",
    "    max_page_count=MAX_PAGES,\n",
    "    start_urls=START_URLS,\n",
    "    output_file=\"output.json\",\n",
    "    extract_rules=r'.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Documents\n",
    "\n",
    "Now we load the website crawl and turn it into LangChain documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "import json\n",
    "\n",
    "\n",
    "with open(\"output.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=d['body'], \n",
    "        id=d['url'],\n",
    "        metadata={\n",
    "            'title': d['title'], \n",
    "            'keywords': d['keywords'],\n",
    "            'description': d['description'],\n",
    "            'url': d['url']\n",
    "        }\n",
    "    ) for d in data\n",
    "]\n",
    "print(len(documents))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Documents into Segments\n",
    "\n",
    "Generally a web page is too large and diverse to be useful in a RAG chain.  Instead we break the document up into segments.  LangChain provides support for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=256,\n",
    "    chunk_overlap=64,\n",
    ")\n",
    "\n",
    "segments = text_splitter.split_documents(documents)\n",
    "print(len(segments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose an Embedding\n",
    "\n",
    "Here we're using the GPT4All package and loading one of its smaller models.  Don't worry if you see messages about CUDA libraries being unavailable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "\n",
    "embeddings = GPT4AllEmbeddings(model_name=\"all-MiniLM-L6-v2.gguf2.f16.gguf\")\n",
    "embeddings_dim = len(embeddings.embed_query(\"test\"))\n",
    "print(f\"Embeddings dimension: {embeddings_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to ApertureDB\n",
    "\n",
    "For the next part, we need access to a specific ApertureDB instance.\n",
    "There are several ways to set this up.\n",
    "The code provided here will accept ApertureDB connection information as a JSON string.\n",
    "See our [Configuration](https://docs.aperturedata.io/Setup/client/configuration) help page for more options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! adb config create --from-json --active "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a LangChain vectorstore using ApertureDB.\n",
    "We use the default client configuration that we have already set up.\n",
    "\n",
    "If you want to create more than one version of the embeddings, then change the `DESCRIPTOR_SET` name.\n",
    "\n",
    "See [AddDescriptorSet](https://docs.aperturedata.io/query_language/Reference/descriptor_commands/desc_set_commands/AddDescriptorSet) for more information about selecting an engine and metric.\n",
    "\n",
    "We use the embeddings object we created above, which will be used when we add documents to the vectorstore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import ApertureDB\n",
    "\n",
    "DESCRIPTOR_SET = 'my_website'\n",
    "\n",
    "vectorstore = ApertureDB(\n",
    "    embeddings=embeddings,\n",
    "    descriptor_set=DESCRIPTOR_SET,\n",
    "    dimensions=embeddings_dim,\n",
    "    engine=\"HNSW\",\n",
    "    metric=\"CS\",\n",
    "    log_level=\"INFO\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the documents into the vectorstore\n",
    "\n",
    "Finally, we come to the part where we load the documents into the vectorstore.\n",
    "Again, this will take a little while to run.\n",
    "\n",
    "The full process takes a while, so we've restricted it here to a few thousand documents so you can progress through the notebook.\n",
    "You can remove this limit and go for lunch instead.\n",
    "\n",
    "Once you add the documents, your ApertureDB instance will be hard at work building a high-performance index for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = vectorstore.add_documents(segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out how many documents are in our vectorstore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(json.dumps([ d for d in ApertureDB.list_vectorstores() if d['_name'] == DESCRIPTOR_SET ], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy up\n",
    "\n",
    "If you want to tidy up and restore your ApertureDB instance to before, you can delete the vectorstore.\n",
    "\n",
    "We've deliberately left this next box not executable so you can go on to use your database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ApertureDB.delete_vectorstore(DESCRIPTOR_SET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next?\n",
    "\n",
    "Next you want to use this vectorstore to drive a RAG (Retrieval-Augmented Generation) chain.\n",
    "\n",
    "See [Building a RAG Chain from a Website](https://docs.aperturedata.io/HowToGuides/Applications/website_search)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further information\n",
    "\n",
    "* [LangChain vectorstore integration](https://python.langchain.com/api_reference/community/vectorstores/langchain_community.vectorstores.aperturedb.ApertureDB.html)\n",
    "* [ApertureDB documentation website](https://docs.aperturedata.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
